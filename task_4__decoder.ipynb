{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 20]), torch.Size([4, 3, 20]), torch.Size([4, 3, 20]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = torch.nn.LSTM(50, 20, 4)\n",
    "input_tensor = torch.randn(5, 3, 50)\n",
    "h0 = torch.randn(4, 3, 20)\n",
    "c0 = torch.randn(4, 3, 20)\n",
    "output, (hn, cn) = rnn(input_tensor, (h0, c0))\n",
    "output.shape, hn.shape, cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randint(0, 10, (2, 5)).long()+4\n",
    "padded = torch.nn.functional.pad(input=input_tensor, pad=(0, 5), mode='constant', value=2)\n",
    "emb = torch.nn.Embedding(\n",
    "    num_embeddings=14,\n",
    "    embedding_dim=20,\n",
    "    padding_idx=2\n",
    ")\n",
    "embeded = emb(input_tensor)\n",
    "print(emb(input_tensor).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13,  4,  5,  8,  5],\n",
       "        [12, 11, 12,  6,  7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чистый Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderLSTM(\n",
      "  (LSTM): LSTM(31, 17, num_layers=7)\n",
      "  (fc): Linear(in_features=17, out_features=41, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedding_size: int,  # размерность векторов в который преобразуется какждый элемент последовательности \n",
    "        hidden_size: int,  # размерность векторов на выходе\n",
    "        num_layers: int,  # число скрытых состояний\n",
    "        output_size: int,  # размер выхода\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.LSTM = torch.nn.LSTM(\n",
    "            self.embedding_size, \n",
    "            hidden_size, num_layers\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(\n",
    "            self.hidden_size, \n",
    "            self.output_size\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x,  # токен последоательности\n",
    "        hidden_state,  # предыдущие скрытые состояния\n",
    "        cell_state  # предыдущие состояния ячейки (короткой памяти)\n",
    "    ):\n",
    "        x = x.unsqueeze(0)  # x.shape == (1, 1, 31)\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(x, (hidden_state, cell_state))\n",
    "        predictions = self.fc(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        return predictions, hidden_state, cell_state\n",
    "\n",
    "decoder_embedding_size = 31\n",
    "hidden_size = 17\n",
    "num_layers = 7\n",
    "output_size = 41\n",
    "\n",
    "decoder_lstm = DecoderLSTM(decoder_embedding_size, hidden_size, num_layers, output_size)\n",
    "print(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10]),\n",
       " torch.Size([1, 41]),\n",
       " torch.Size([7, 1, 17]),\n",
       " torch.Size([7, 1, 17]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 31)\n",
    "hidden_state = torch.randn(7, 1, 17)\n",
    "cell_state = torch.randn(7, 1, 17)\n",
    "outputs, hidden_state, cell_state = decoder_lstm(input_tensor, hidden_state, cell_state)\n",
    "padded.shape, outputs.shape, hidden_state.shape, cell_state.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Со встроенной векторизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderLSTM(\n",
      "  (embedding): Embedding(23, 31, padding_idx=2)\n",
      "  (LSTM): LSTM(31, 17, num_layers=7)\n",
      "  (fc): Linear(in_features=17, out_features=41, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size: int,  # размер словаря  \n",
    "        embedding_size: int,  # размерность векторов в который преобразуется какждый элемент последовательности \n",
    "        hidden_size: int,  # размерность векторов на выходе\n",
    "        num_layers: int,  # число скрытых состояний\n",
    "        output_size: int,  # размер выхода\n",
    "        pad_idx: int=2\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            self.vocab_size, \n",
    "            self.embedding_size,\n",
    "            padding_idx=pad_idx\n",
    "        )\n",
    "        self.LSTM = torch.nn.LSTM(\n",
    "            self.embedding_size, \n",
    "            hidden_size, num_layers\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(\n",
    "            self.hidden_size, \n",
    "            self.output_size\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x,  # токен последоательности\n",
    "        hidden_state,  # предыдущие скрытые состояния\n",
    "        cell_state  # предыдущие состояния ячейки (короткой памяти)\n",
    "    ):\n",
    "        x = x.unsqueeze(0)  # x.shape == (1, 1)\n",
    "        embedding = self.embedding(x)  # embedding.shape == (1, 1, 31)\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
    "        predictions = self.fc(outputs)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        return predictions, hidden_state, cell_state\n",
    "\n",
    "vocab_size_decoder = 23\n",
    "decoder_embedding_size = 31\n",
    "hidden_size = 17\n",
    "num_layers = 7\n",
    "output_size = 41\n",
    "\n",
    "decoder_lstm = DecoderLSTM(vocab_size_decoder, decoder_embedding_size, hidden_size, num_layers, output_size)\n",
    "print(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10]),\n",
       " torch.Size([1, 41]),\n",
       " torch.Size([7, 1, 17]),\n",
       " torch.Size([7, 1, 17]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randint(4, 23, (1, 1)).long()[0]\n",
    "hidden_state = torch.randn(7, 1, 17)\n",
    "cell_state = torch.randn(7, 1, 17)\n",
    "outputs, hidden_state, cell_state = decoder_lstm(input_tensor, hidden_state, cell_state)\n",
    "padded.shape, outputs.shape, hidden_state.shape, cell_state.shape "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RGR_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
